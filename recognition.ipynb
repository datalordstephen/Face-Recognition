{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary modules\n",
    "import cv2\n",
    "import face_recognition\n",
    "from imutils import paths\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring empty lists to store names and encodings later\n",
    "known_names = []\n",
    "known_encodings = []\n",
    "\n",
    "# using the paths module to list out and find all images in the \"Images\" directory\n",
    "image_paths = list(paths.list_images('Images'))\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Images\\\\Azeez\\\\azeez (1).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (2).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (3).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (4).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (5).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (6).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (7).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (8).jpg',\n",
       " 'Images\\\\Azeez\\\\azeez (9).jpg',\n",
       " 'Images\\\\Biden\\\\biden1.jpeg',\n",
       " 'Images\\\\Biden\\\\biden10.jpeg',\n",
       " 'Images\\\\Biden\\\\biden11.jpeg',\n",
       " 'Images\\\\Biden\\\\biden12.jpeg',\n",
       " 'Images\\\\Biden\\\\biden13.jpeg',\n",
       " 'Images\\\\Biden\\\\biden14.jpeg',\n",
       " 'Images\\\\Biden\\\\biden15.jpeg',\n",
       " 'Images\\\\Biden\\\\biden17.jpeg',\n",
       " 'Images\\\\Biden\\\\biden18.jpeg',\n",
       " 'Images\\\\Biden\\\\biden19.jpeg',\n",
       " 'Images\\\\Biden\\\\biden2.jpeg',\n",
       " 'Images\\\\Biden\\\\biden20.jpeg',\n",
       " 'Images\\\\Biden\\\\biden21.jpeg',\n",
       " 'Images\\\\Biden\\\\biden22.jpeg',\n",
       " 'Images\\\\Biden\\\\biden3.jpeg',\n",
       " 'Images\\\\Biden\\\\biden4.jpeg',\n",
       " 'Images\\\\Biden\\\\biden6.jpeg',\n",
       " 'Images\\\\Biden\\\\biden7.jpeg',\n",
       " 'Images\\\\Biden\\\\biden8.jpeg',\n",
       " 'Images\\\\Biden\\\\bidn9.jpeg',\n",
       " 'Images\\\\Damola\\\\Damola (1).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (2).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (3).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (4).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (5).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (6).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (7).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (8).jpg',\n",
       " 'Images\\\\Damola\\\\Damola (9).jpg',\n",
       " 'Images\\\\Obama\\\\b03.jpeg',\n",
       " 'Images\\\\Obama\\\\b08.jpeg',\n",
       " 'Images\\\\Obama\\\\b09.jpeg',\n",
       " 'Images\\\\Obama\\\\b12.jpeg',\n",
       " 'Images\\\\Obama\\\\b13.jpeg',\n",
       " 'Images\\\\Obama\\\\b14.jpeg',\n",
       " 'Images\\\\Obama\\\\b16.jpeg',\n",
       " 'Images\\\\Obama\\\\b17.jpeg',\n",
       " 'Images\\\\Obama\\\\b18.jpeg',\n",
       " 'Images\\\\Obama\\\\b19.jpeg',\n",
       " 'Images\\\\Obama\\\\b20.jpeg',\n",
       " 'Images\\\\Obama\\\\bo1.jpeg',\n",
       " 'Images\\\\Obama\\\\bo11.jpeg',\n",
       " 'Images\\\\Obama\\\\bo2.jpeg',\n",
       " 'Images\\\\Obama\\\\bo4.jpeg',\n",
       " 'Images\\\\Obama\\\\bo5.jpeg',\n",
       " 'Images\\\\Obama\\\\bo6.jpeg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing the images \n",
    "image_paths[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrollment Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"training\" stage. The names and face encodings of the images are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through the images and saving the individual names\n",
    "for image in image_paths:\n",
    "    name = image.split('\\\\')[1]\n",
    "    bgr_img = cv2.imread(image)\n",
    "    \n",
    "    # converting to RBG due to using the face_recognition library as cv2 reads images in BGR\n",
    "    rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # finding the locations of faces based on their facial features and encoding the faces \n",
    "    faces = face_recognition.face_locations(rgb_img, model='hog')\n",
    "    encodings = face_recognition.face_encodings(rgb_img, faces)\n",
    "    \n",
    "    # saving the individual encodings and names to the pre-defined lists \n",
    "    for encoding in encodings:\n",
    "        known_names.append(name)\n",
    "        known_encodings.append(encoding)\n",
    "        \n",
    "# saving all encodings and names into a dictionary and serializing them into a pickled file \n",
    "data = {'names' : known_names, 'encodings' : known_encodings}\n",
    "with open('face_encodings','wb') as f:\n",
    "    f.write(pickle.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the stage where the serialized encodings are then deserialized and used to check new faces and flag them as recognized or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the test image, resizing it and changing it to RBG\n",
    "new_image = cv2.imread('Test Images/group (1).jpg')\n",
    "new_image = cv2.resize(new_image, None, fx= 0.25, fy = 0.25)\n",
    "rgb_new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# finding the face loactions and encodings of the test image (if any)\n",
    "faces = face_recognition.face_locations(rgb_new_image)\n",
    "encodings = face_recognition.face_encodings(rgb_new_image, faces)\n",
    "\n",
    "# deserializing our encoding file \n",
    "with open('face_encodings', 'rb') as f:\n",
    "    data = pickle.loads(f.read())\n",
    "\n",
    "# creating empty structures\n",
    "count_names = {}\n",
    "names = []\n",
    "\n",
    "# comparing the located faces in the test image to the serialized ones \n",
    "for encoding in encodings:\n",
    "    \n",
    "    # computing the distance between the serialized faces and the test face\n",
    "    distances = face_recognition.face_distance(data['encodings'], encoding)\n",
    "    min_value = np.min(distances)\n",
    "    \n",
    "    # setting a threshold value for the distance\n",
    "    if min_value > 0.5:\n",
    "        name = 'Unknown'\n",
    "    else:\n",
    "        i = np.argmin(distances)\n",
    "        name = data['names'][i]\n",
    "    names.append(name)\n",
    "\n",
    "# drawing bounding boxes on all faces and labelling them \n",
    "face_names = list(zip(faces, names))\n",
    "for((top, right, bottom, left), name) in face_names:\n",
    "    cv2.rectangle(new_image, (left, top), (right, bottom), (255,0,0), 3)\n",
    "    cv2.putText(new_image,name.upper(), (left-2,top-3), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 1)\n",
    "    \n",
    "cv2.imshow('Picture', new_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a72b5b61e241fda0c55c5dd979a1f7412aa055bd794be867cb695bc8ffbf51ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('face')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
